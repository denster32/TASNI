#!/usr/bin/env python3
"""
TASNI Pipeline: Bayesian False-Positive Modeling & Error Propagation
====================================================================

Uses PyMC for Bayesian modeling of false-positive probability and error propagation
on scores/distances/Teff. Integrates Sonora Cholla priors, parallax uncertainties.

Input: tier5 or ML-ranked parquet
Output: posteriors.parquet with p_fp (false positive prob), Teff_posterior, dist_posterior

Usage:
  poetry run python src/tasni/pipeline/bayesian_selection.py --input data/processed/ml/ranked_tier5_improved.parquet --output data/processed/ml/bayesian_posteriors.parquet
"""

import argparse
import logging
from pathlib import Path

import arviz as az
import numpy as np
import pandas as pd
import pymc as pm
import pytensor.tensor as pt

from tasni.core.seeds import DEFAULT_RANDOM_SEED

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def bayesian_fp_model(features, score_col="improved_composite_score"):
    """Bayesian false-positive rate modeling."""
    n = len(features)
    scores = features[score_col].values

    with pm.Model() as model:
        # Priors: base FP rate low for high scores
        fp_base = pm.Beta("fp_base", alpha=1, beta=10)  # ~0.09 mean
        score_effect = pm.Normal("score_effect", 0, 1)

        # Likelihood: score ~ logit(fp_rate)
        logit_fp = fp_base + score_effect * (scores - scores.mean()) / scores.std()
        fp_prob = pt.sigmoid(logit_fp)
        obs = pm.Bernoulli(
            "obs", p=fp_prob, observed=np.zeros(n)
        )  # Pseudo-obs: assume no known FPs

        trace = pm.sample(1000, tune=500, random_seed=DEFAULT_RANDOM_SEED, progressbar=False)

    # Posterior p(fp | score) for top candidates
    fp_posterior = az.summary(trace, hdi_prob=0.95)["fp_base"].mean
    return fp_posterior, trace


def _distance_posterior_mc(
    parallax_mas: float,
    parallax_err_mas: float,
    n_mc: int,
    rng: np.random.Generator,
) -> tuple[float, float, float, float]:
    """
    Monte Carlo posterior for distance from parallax, truncated at positive parallax.
    """
    if not np.isfinite(parallax_mas) or not np.isfinite(parallax_err_mas):
        return np.nan, np.nan, np.nan, np.nan
    if parallax_mas <= 0:
        return np.nan, np.nan, np.nan, np.nan
    if parallax_err_mas <= 0:
        parallax_err_mas = max(abs(parallax_mas) * 0.2, 1e-3)

    samples = rng.normal(parallax_mas, parallax_err_mas, size=n_mc)
    samples = samples[samples > 0]
    if len(samples) < max(50, n_mc // 20):
        # Too much mass at non-physical parallax <= 0: return NaN instead of unstable estimates.
        return np.nan, np.nan, np.nan, np.nan

    distances = 1000.0 / samples
    mean = float(np.mean(distances))
    std = float(np.std(distances, ddof=1))
    p16, p84 = np.percentile(distances, [16, 84])
    return mean, std, float(p16), float(p84)


def propagate_errors(
    df: pd.DataFrame,
    parallax_col: str = "parallax",
    teff_col: str = "teff_estimate",
    n_mc: int = 2000,
    random_seed: int = DEFAULT_RANDOM_SEED,
) -> pd.DataFrame:
    """Error propagation with Monte Carlo distance posteriors and Teff uncertainty tracking."""
    parallax = df[parallax_col].to_numpy(dtype=float)
    if "parallax_error" in df.columns:
        parallax_err = df["parallax_error"].to_numpy(dtype=float)
    else:
        # Conservative fallback for missing error column.
        parallax_err = np.maximum(np.abs(parallax) * 0.2, 1e-3)

    rng = np.random.default_rng(random_seed)
    dist_mean = np.full(len(df), np.nan, dtype=float)
    dist_std = np.full(len(df), np.nan, dtype=float)
    dist_p16 = np.full(len(df), np.nan, dtype=float)
    dist_p84 = np.full(len(df), np.nan, dtype=float)

    for idx, (plx, plx_err) in enumerate(zip(parallax, parallax_err, strict=False)):
        mean, std, p16, p84 = _distance_posterior_mc(
            parallax_mas=plx,
            parallax_err_mas=plx_err,
            n_mc=n_mc,
            rng=rng,
        )
        dist_mean[idx] = mean
        dist_std[idx] = std
        dist_p16[idx] = p16
        dist_p84[idx] = p84

    df["dist_posterior_mean"] = dist_mean
    df["dist_posterior_std"] = dist_std
    df["dist_posterior_p16"] = dist_p16
    df["dist_posterior_p84"] = dist_p84

    teff = df[teff_col].to_numpy(dtype=float)
    teff_err_col = next(
        (c for c in ("teff_error", "T_eff_err", "teff_err") if c in df.columns), None
    )
    if teff_err_col:
        teff_err = df[teff_err_col].fillna(50.0).to_numpy(dtype=float)
    else:
        teff_err = np.full(len(df), 50.0, dtype=float)

    df["teff_posterior_mean"] = teff
    df["teff_posterior_std"] = teff_err
    df["teff_posterior_p16"] = teff - teff_err
    df["teff_posterior_p84"] = teff + teff_err

    return df


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", default="data/processed/ml/ranked_tier5_improved.parquet")
    parser.add_argument("--output", default="data/processed/ml/bayesian_posteriors.parquet")
    parser.add_argument("--top-n", type=int, default=1000)
    args = parser.parse_args()

    df = pd.read_parquet(args.input).head(args.top_n)
    logger.info(f"Loaded {len(df)} candidates for Bayesian modeling")

    # FP modeling (simplified)
    fp_mean, trace = bayesian_fp_model(df)
    df["p_false_positive"] = fp_mean  # Broadcast mean for simplicity

    # Error prop
    df = propagate_errors(df)

    # Save
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    df.to_parquet(output_path, index=False)

    logger.info(f"Bayesian posteriors saved: mean p_FP={fp_mean:.3f}, top {args.top_n} updated")
    logger.info(
        f"Sample: dist= {df['dist_posterior_mean'].head().mean():.0f}Â±{df['dist_posterior_std'].head().mean():.0f} pc"
    )


if __name__ == "__main__":
    main()
